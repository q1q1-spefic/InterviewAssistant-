"""
é«˜çº§å®ä½“æå–å™¨
æ”¯æŒå¤šè¯­è¨€ã€ä¸Šä¸‹æ–‡ç†è§£ã€å†²çªæ£€æµ‹å’Œæ¨¡ç³ŠåŒ¹é…
"""
import re
import json
import time
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum
from loguru import logger

class EntityType(Enum):
    """å®ä½“ç±»å‹"""
    PERSON = "person"           # äººå
    FAMILY_ROLE = "family_role" # å®¶åº­è§’è‰²
    LOCATION = "location"       # åœ°ç‚¹
    AGE = "age"                # å¹´é¾„
    OCCUPATION = "occupation"   # èŒä¸š
    SKILL = "skill"            # æŠ€èƒ½
    PREFERENCE = "preference"   # åå¥½
    PHYSICAL = "physical"       # èº«ä½“ç‰¹å¾
    EDUCATION = "education"     # æ•™è‚²
    TIME = "time"              # æ—¶é—´

class ConflictType(Enum):
    """å†²çªç±»å‹"""
    CONTRADICTION = "contradiction"  # ç›´æ¥çŸ›ç›¾
    UPDATE = "update"               # ä¿¡æ¯æ›´æ–°
    CLARIFICATION = "clarification" # æ¾„æ¸…è¡¥å……
    DIFFERENT_CONTEXT = "different_context"  # ä¸åŒè¯­å¢ƒ

@dataclass
class ExtractedEntity:
    """æå–çš„å®ä½“"""
    text: str
    entity_type: EntityType
    confidence: float
    context: str
    normalized_form: str  # æ ‡å‡†åŒ–å½¢å¼
    aliases: List[str]    # åˆ«å
    metadata: Dict[str, Any]

@dataclass
class ConflictInfo:
    """å†²çªä¿¡æ¯"""
    entity: str
    conflict_type: ConflictType
    old_value: Any
    new_value: Any
    confidence: float
    resolution: str

class AdvancedEntityExtractor:
    """é«˜çº§å®ä½“æå–å™¨"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        
        # å¤šè¯­è¨€æ”¯æŒ
        self.language_patterns = {
            "zh": self._init_chinese_patterns(),
            "en": self._init_english_patterns(),
        }
        
        # å®ä½“æ ‡å‡†åŒ–æ˜ å°„
        self.entity_normalizer = {
            "family_roles": {
                "å¼Ÿå¼Ÿ": ["å¼Ÿå¼Ÿ", "å°å¼Ÿ", "å¼Ÿ", "å…„å¼Ÿ"],
                "å¦¹å¦¹": ["å¦¹å¦¹", "å°å¦¹", "å¦¹", "å§å¦¹"],
                "å“¥å“¥": ["å“¥å“¥", "å¤§å“¥", "å“¥", "å…„å¼Ÿ"],
                "å§å§": ["å§å§", "å¤§å§", "å§", "å§å¦¹"],
                "å¦ˆå¦ˆ": ["å¦ˆå¦ˆ", "æ¯äº²", "è€å¦ˆ", "å¦ˆ", "æ¯äº²å¤§äºº"],
                "çˆ¸çˆ¸": ["çˆ¸çˆ¸", "çˆ¶äº²", "è€çˆ¸", "çˆ¸", "çˆ¶äº²å¤§äºº"],
            }
        }
        
        # å†²çªæ£€æµ‹è§„åˆ™
        self.conflict_rules = self._init_conflict_rules()
        
        logger.info("ğŸ” é«˜çº§å®ä½“æå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_chinese_patterns(self) -> Dict[str, List[str]]:
        """åˆå§‹åŒ–ä¸­æ–‡æ¨¡å¼"""
        return {
            "person": [  # æ”¹ä¸ºperson
                r'æˆ‘å«(.{1,4})',
                r'æˆ‘çš„åå­—.*?(.{1,4})',
                r'(.{1,4})æ˜¯æˆ‘.*?',
                r'æˆ‘æ˜¯(.{1,4})',
            ],
            "family_role": [
                r'æˆ‘çš„?(å¼Ÿå¼Ÿ|å¦¹å¦¹|å“¥å“¥|å§å§|å¦ˆå¦ˆ|çˆ¸çˆ¸|æ¯äº²|çˆ¶äº²)',
                r'(å¼Ÿå¼Ÿ|å¦¹å¦¹|å“¥å“¥|å§å§|å¦ˆå¦ˆ|çˆ¸çˆ¸|æ¯äº²|çˆ¶äº²).*?æˆ‘',
            ],
            "age": [
                r'(\d+)\s*å²',
                r'å¹´é¾„.*?(\d+)',
                r'ä»Šå¹´.*?(\d+)',
            ],
            "location": [
                r'ä½åœ¨(.{1,10})',
                r'å®¶åœ¨(.{1,10})',
                r'æ¥è‡ª(.{1,10})',
                r'åœ¨(.{1,10})å·¥ä½œ',
            ],
            "occupation": [
                r'æˆ‘æ˜¯(.{1,10}?(?:å¸ˆ|å‘˜|å®¶|ç”Ÿ|å·¥))',
                r'èŒä¸š.*?(.{1,10})',
                r'å·¥ä½œ.*?(.{1,10})',
            ]
        }
    
    def _init_english_patterns(self) -> Dict[str, List[str]]:
        """åˆå§‹åŒ–è‹±æ–‡æ¨¡å¼"""
        return {
            "person_name": [
                r'my name is (\w+)',
                r'i am (\w+)',
                r'(\w+) is my',
            ],
            "family_role": [
                r'my (brother|sister|mother|father|mom|dad)',
                r'(brother|sister|mother|father|mom|dad)',
            ],
            "age": [
                r'(\d+)\s*years?\s*old',
                r'age.*?(\d+)',
            ]
        }
    
    def _init_conflict_rules(self) -> Dict[str, Dict]:
        """åˆå§‹åŒ–å†²çªæ£€æµ‹è§„åˆ™"""
        return {
            "family_role_conflicts": {
                "å¼Ÿå¼Ÿ": ["å¦¹å¦¹", "å§å§", "å“¥å“¥"],
                "å¦¹å¦¹": ["å¼Ÿå¼Ÿ", "å“¥å“¥", "å§å§"],
                "å“¥å“¥": ["å¼Ÿå¼Ÿ", "å¦¹å¦¹", "å§å§"],
                "å§å§": ["å¼Ÿå¼Ÿ", "å¦¹å¦¹", "å“¥å“¥"],
            },
            "occupation_conflicts": {
                # ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œä¸€ä¸ªäººåªèƒ½æœ‰ä¸€ä¸ªä¸»è¦èŒä¸š
                "mutual_exclusive": True
            },
            "age_conflicts": {
                # å¹´é¾„åªèƒ½å¢é•¿ï¼Œä¸èƒ½å‡å°‘ï¼ˆé™¤éæ˜¯æ›´æ­£é”™è¯¯ï¼‰
                "monotonic": True,
                "max_change_per_day": 0.01  # æ¯å¤©æœ€å¤§å˜åŒ–
            }
        }
    
    async def extract_entities_advanced(self, text: str, context: str = "", 
                                      language: str = "auto") -> Tuple[List[ExtractedEntity], List[ConflictInfo]]:
        """é«˜çº§å®ä½“æå–"""
        try:
            logger.debug(f"ğŸ” é«˜çº§å®ä½“æå–: {text}")
            
            # 1. è¯­è¨€æ£€æµ‹
            detected_lang = self._detect_language(text) if language == "auto" else language
            
            # 2. è§„åˆ™æå–
            rule_entities = await self._rule_based_extraction(text, detected_lang)
            
            # 3. AIå¢å¼ºæå–
            ai_entities = await self._ai_enhanced_extraction(text, context, detected_lang)
            
            # 4. å®ä½“èåˆå’Œæ ‡å‡†åŒ–
            merged_entities = await self._merge_and_normalize_entities(rule_entities + ai_entities)
            
            # 5. å†²çªæ£€æµ‹
            conflicts = await self._detect_conflicts(merged_entities, text)
            
            # 6. è´¨é‡è¿‡æ»¤
            filtered_entities = self._filter_by_quality(merged_entities)
            
            logger.info(f"âœ… æå–å®Œæˆ: {len(filtered_entities)} ä¸ªå®ä½“, {len(conflicts)} ä¸ªå†²çª")
            return filtered_entities, conflicts
            
        except Exception as e:
            logger.error(f"é«˜çº§å®ä½“æå–å¤±è´¥: {e}")
            return [], []
    
    def _detect_language(self, text: str) -> str:
        """æ£€æµ‹è¯­è¨€"""
        # ç®€å•çš„è¯­è¨€æ£€æµ‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        
        if chinese_chars > english_chars:
            return "zh"
        elif english_chars > 0:
            return "en"
        else:
            return "zh"  # é»˜è®¤ä¸­æ–‡
    
    async def _rule_based_extraction(self, text: str, language: str) -> List[ExtractedEntity]:
        """åŸºäºè§„åˆ™çš„å®ä½“æå–"""
        entities = []
        patterns = self.language_patterns.get(language, {})
        
        for entity_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    entity_text = match.group(1) if match.groups() else match.group(0)
                    
                    # æ ‡å‡†åŒ–
                    normalized = self._normalize_entity(entity_text, entity_type)
                    aliases = self._get_aliases(normalized, entity_type)
                    
                    entity = ExtractedEntity(
                        text=entity_text,
                        entity_type=EntityType(entity_type.replace("_", "_")),
                        confidence=0.9,  # è§„åˆ™æå–é«˜ç½®ä¿¡åº¦
                        context=text,
                        normalized_form=normalized,
                        aliases=aliases,
                        metadata={"extraction_method": "rule", "pattern": pattern}
                    )
                    entities.append(entity)
        
        return entities
    
    async def _ai_enhanced_extraction(self, text: str, context: str, language: str) -> List[ExtractedEntity]:
        """AIå¢å¼ºå®ä½“æå–"""
        try:
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé«˜çº§å®ä½“æå–ä¸“å®¶ï¼Œè¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“ä¿¡æ¯ã€‚

æ–‡æœ¬: {text}
ä¸Šä¸‹æ–‡: {context}

**ç‰¹åˆ«æ³¨æ„èº«ä»½å…³è”ï¼š**
- å¦‚æœæ–‡æœ¬æ˜¯"æˆ‘å«X"ï¼Œæå–personå®ä½“"X"ï¼Œå¹¶æ ‡è®°ä¸ºuser_identity
- å¦‚æœæ–‡æœ¬æ˜¯"Xå¤šå°‘å²"ä¸”Xæ˜¯å·²çŸ¥çš„ç”¨æˆ·å§“åï¼Œå»ºç«‹å…³è”

è¯·æå–ä»¥ä¸‹ç±»å‹çš„å®ä½“ï¼š
- person: äººåï¼ˆç‰¹åˆ«æ ‡æ³¨æ˜¯å¦ä¸ºç”¨æˆ·æœ¬äººï¼‰
- family_role: å®¶åº­è§’è‰²
- location: åœ°ç‚¹  
- age: å¹´é¾„
- occupation: èŒä¸š
- skill: æŠ€èƒ½
- preference: åå¥½
- physical: èº«ä½“ç‰¹å¾
- education: æ•™è‚²
- time: æ—¶é—´

è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "entities": [
        {{
            "text": "æå–çš„æ–‡æœ¬",
            "type": "å®ä½“ç±»å‹",
            "confidence": 0.0-1.0,
            "normalized": "æ ‡å‡†åŒ–å½¢å¼",
            "aliases": ["åˆ«å1", "åˆ«å2"],
            "is_user_identity": true/false
        }}
    ]
}}
"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.1
            )
            
            if response.choices:
                result_text = response.choices[0].message.content.strip()
                
                # æ¸…ç†æ ¼å¼
                if "```json" in result_text:
                    result_text = result_text.split("```json")[1].split("```")[0].strip()
                
                try:
                    result_data = json.loads(result_text)
                    entities = []
                    
                    for entity_data in result_data.get("entities", []):
                        entity = ExtractedEntity(
                            text=entity_data["text"],
                            entity_type=EntityType(entity_data["type"]),
                            confidence=entity_data["confidence"],
                            context=text,
                            normalized_form=entity_data["normalized"],
                            aliases=entity_data.get("aliases", []),
                            metadata={"extraction_method": "ai"}
                        )
                        entities.append(entity)
                    
                    return entities
                    
                except json.JSONDecodeError:
                    logger.warning("AIå®ä½“æå–JSONè§£æå¤±è´¥")
                    return []
            
            return []
            
        except Exception as e:
            logger.error(f"AIå®ä½“æå–å¤±è´¥: {e}")
            return []
    
    def _normalize_entity(self, entity_text: str, entity_type: str) -> str:
        """å®ä½“æ ‡å‡†åŒ–"""
        if entity_type == "family_role":
            for standard, aliases in self.entity_normalizer["family_roles"].items():
                if entity_text in aliases:
                    return standard
        
        return entity_text.strip()
    
    def _get_aliases(self, normalized_entity: str, entity_type: str) -> List[str]:
        """è·å–å®ä½“åˆ«å"""
        if entity_type == "family_role":
            return self.entity_normalizer["family_roles"].get(normalized_entity, [])
        
        return []
    
    async def _merge_and_normalize_entities(self, entities: List[ExtractedEntity]) -> List[ExtractedEntity]:
        """åˆå¹¶å’Œæ ‡å‡†åŒ–å®ä½“"""
        # æŒ‰æ ‡å‡†åŒ–å½¢å¼åˆ†ç»„
        entity_groups = {}
        
        for entity in entities:
            key = f"{entity.entity_type.value}:{entity.normalized_form}"
            if key not in entity_groups:
                entity_groups[key] = []
            entity_groups[key].append(entity)
        
        # åˆå¹¶åŒç±»å®ä½“
        merged_entities = []
        for group in entity_groups.values():
            if len(group) == 1:
                merged_entities.append(group[0])
            else:
                # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„
                best_entity = max(group, key=lambda x: x.confidence)
                # åˆå¹¶åˆ«å
                all_aliases = set()
                for entity in group:
                    all_aliases.update(entity.aliases)
                    all_aliases.add(entity.text)
                
                best_entity.aliases = list(all_aliases)
                merged_entities.append(best_entity)
        
        return merged_entities
    
    async def _detect_conflicts(self, entities: List[ExtractedEntity], text: str) -> List[ConflictInfo]:
        """æ£€æµ‹å†²çª"""
        conflicts = []
        
        # å®¶åº­è§’è‰²å†²çªæ£€æµ‹
        family_roles = [e for e in entities if e.entity_type == EntityType.FAMILY_ROLE]
        if len(family_roles) > 1:
            conflict = await self._detect_family_role_conflict(family_roles, text)
            if conflict:
                conflicts.append(conflict)
        
        # å¹´é¾„å†²çªæ£€æµ‹
        ages = [e for e in entities if e.entity_type == EntityType.AGE]
        if ages:
            conflict = await self._detect_age_conflict(ages[0], text)
            if conflict:
                conflicts.append(conflict)
        
        return conflicts
    
    async def _detect_family_role_conflict(self, family_roles: List[ExtractedEntity], text: str) -> Optional[ConflictInfo]:
        """æ£€æµ‹å®¶åº­è§’è‰²å†²çª"""
        if len(family_roles) < 2:
            return None
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨äº’æ–¥è§’è‰²
        role_names = [entity.normalized_form for entity in family_roles]
        
        for i, role1 in enumerate(role_names):
            for j, role2 in enumerate(role_names[i+1:], i+1):
                if role2 in self.conflict_rules["family_role_conflicts"].get(role1, []):
                    return ConflictInfo(
                        entity="family_role",
                        conflict_type=ConflictType.CONTRADICTION,
                        old_value=role1,
                        new_value=role2,
                        confidence=0.8,
                        resolution="éœ€è¦ç”¨æˆ·æ¾„æ¸…"
                    )
        
        return None
    
    async def _detect_age_conflict(self, age_entity: ExtractedEntity, text: str) -> Optional[ConflictInfo]:
        """æ£€æµ‹å¹´é¾„å†²çª"""
        # è¿™é‡Œéœ€è¦ä¸å†å²æ•°æ®å¯¹æ¯”ï¼Œæš‚æ—¶è¿”å›None
        # åœ¨å®é™…å®ç°ä¸­ï¼Œä¼šæŸ¥è¯¢æ•°æ®åº“ä¸­çš„å†å²å¹´é¾„ä¿¡æ¯
        return None
    
    def _filter_by_quality(self, entities: List[ExtractedEntity]) -> List[ExtractedEntity]:
        """è´¨é‡è¿‡æ»¤"""
        return [entity for entity in entities if entity.confidence >= 0.5]
    
    async def resolve_conflict(self, conflict: ConflictInfo, user_choice: str = "auto") -> str:
        """è§£å†³å†²çª"""
        try:
            if user_choice == "auto":
                # è‡ªåŠ¨è§£å†³ç­–ç•¥
                if conflict.conflict_type == ConflictType.CONTRADICTION:
                    return "keep_new"  # ä¿ç•™æ–°ä¿¡æ¯
                elif conflict.conflict_type == ConflictType.UPDATE:
                    return "merge"  # åˆå¹¶ä¿¡æ¯
                else:
                    return "clarify"  # éœ€è¦æ¾„æ¸…
            else:
                return user_choice
                
        except Exception as e:
            logger.error(f"å†²çªè§£å†³å¤±è´¥: {e}")
            return "keep_old"