"""
è®°å¿†å…³è”å›¾è°±ç®¡ç†å™¨
ä½¿ç”¨OpenAIæ™ºèƒ½æ„å»ºè®°å¿†ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œå®ç°è®°å¿†ä¸²è”å’Œæ¨ç†
"""
import json
import time
import sqlite3
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from loguru import logger

class RelationType(Enum):
    """å…³è”ç±»å‹"""
    IDENTITY = "identity"           # èº«ä»½å…³è”ï¼šå¼ ä¸‰ â†’ ç¨‹åºå‘˜
    FAMILY = "family"              # å®¶åº­å…³è”ï¼šæ˜Ÿæ˜Ÿ â†’ å¼Ÿå¼Ÿ
    LOCATION = "location"          # åœ°ç‚¹å…³è”ï¼šå¼ ä¸‰ â†’ åŒ—äº¬
    SKILL = "skill"               # æŠ€èƒ½å…³è”ï¼šå¼ ä¸‰ â†’ Python
    PREFERENCE = "preference"      # åå¥½å…³è”ï¼šå¼ ä¸‰ â†’ ç¼–ç¨‹
    WORK = "work"                 # å·¥ä½œå…³è”ï¼šç¨‹åºå‘˜ â†’ ç¼–ç¨‹
    PHYSICAL = "physical"         # èº«ä½“å…³è”ï¼šå¼ ä¸‰ â†’ 180cm
    TEMPORAL = "temporal"         # æ—¶é—´å…³è”ï¼šä»Šå¤© â†’ å·¥ä½œ
    CAUSAL = "causal"            # å› æœå…³è”ï¼šå–œæ¬¢ç¼–ç¨‹ â†’ å­¦Python
    SEMANTIC = "semantic"         # è¯­ä¹‰å…³è”ï¼šç›¸ä¼¼æ¦‚å¿µ

@dataclass
class MemoryNode:
    """è®°å¿†èŠ‚ç‚¹"""
    id: str
    content: str
    memory_type: str
    importance: float
    entities: List[str]  # æå–çš„å®ä½“
    concepts: List[str]  # æå–çš„æ¦‚å¿µ
    timestamp: float

@dataclass
class MemoryEdge:
    """è®°å¿†è¾¹ï¼ˆå…³è”ï¼‰"""
    id: str
    source_memory_id: str
    target_memory_id: str
    relation_type: RelationType
    confidence: float
    description: str
    timestamp: float
    
    def to_dict(self) -> Dict:
        return asdict(self)

@dataclass
class GraphSearchResult:
    """å›¾è°±æœç´¢ç»“æœ"""
    primary_memories: List[MemoryNode]
    related_memories: List[MemoryNode]
    relations: List[MemoryEdge]
    inference_chain: List[str]  # æ¨ç†é“¾

class MemoryGraphManager:
    """è®°å¿†å…³è”å›¾è°±ç®¡ç†å™¨"""
    
    def __init__(self, openai_client, db_connection):
        self.openai_client = openai_client
        self.conn = db_connection
        
        # é…ç½®å‚æ•°
        self.relation_confidence_threshold = 0.7
        self.max_relation_depth = 3
        self.entity_similarity_threshold = 0.8
        
        self._init_graph_storage()
        logger.info("ğŸ•¸ï¸ è®°å¿†å…³è”å›¾è°±ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_graph_storage(self):
        """åˆå§‹åŒ–å›¾è°±å­˜å‚¨"""
        try:
            # åˆ›å»ºè®°å¿†èŠ‚ç‚¹è¡¨
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS memory_nodes (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    memory_type TEXT,
                    importance REAL,
                    entities TEXT,
                    concepts TEXT,
                    timestamp REAL
                )
            """)
            
            # åˆ›å»ºè®°å¿†å…³è”è¡¨
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS memory_edges (
                    id TEXT PRIMARY KEY,
                    source_memory_id TEXT,
                    target_memory_id TEXT,
                    relation_type TEXT,
                    confidence REAL,
                    description TEXT,
                    timestamp REAL,
                    FOREIGN KEY (source_memory_id) REFERENCES memory_nodes (id),
                    FOREIGN KEY (target_memory_id) REFERENCES memory_nodes (id)
                )
            """)
            
            # åˆ›å»ºå®ä½“ç´¢å¼•è¡¨
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS entity_index (
                    entity TEXT,
                    memory_id TEXT,
                    entity_type TEXT,
                    confidence REAL,
                    PRIMARY KEY (entity, memory_id)
                )
            """)
            
            self.conn.commit()
            logger.debug("âœ… å›¾è°±å­˜å‚¨è¡¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å›¾è°±å­˜å‚¨å¤±è´¥: {e}")
    
    async def add_memory_to_graph(self, memory_id: str, content: str, 
                                memory_type: str, importance: float) -> bool:
        """å°†è®°å¿†æ·»åŠ åˆ°å›¾è°±"""
        try:
            logger.debug(f"ğŸ•¸ï¸ æ·»åŠ è®°å¿†åˆ°å›¾è°±: {content}")
            
            # 1. æå–å®ä½“å’Œæ¦‚å¿µ
            entities, concepts = await self._extract_entities_and_concepts(content)
            
            # 2. åˆ›å»ºè®°å¿†èŠ‚ç‚¹
            node = MemoryNode(
                id=memory_id,
                content=content,
                memory_type=memory_type,
                importance=importance,
                entities=entities,
                concepts=concepts,
                timestamp=time.time()
            )
            
            # 3. å­˜å‚¨èŠ‚ç‚¹
            await self._store_memory_node(node)
            
            # 4. æ„å»ºä¸ç°æœ‰è®°å¿†çš„å…³è”
            await self._build_relations_for_new_memory(node)
            
            logger.info(f"âœ… è®°å¿†å›¾è°±æ·»åŠ æˆåŠŸ: {len(entities)} ä¸ªå®ä½“, {len(concepts)} ä¸ªæ¦‚å¿µ")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ è®°å¿†åˆ°å›¾è°±å¤±è´¥: {e}")
            return False
    
    async def _extract_entities_and_concepts(self, content: str) -> Tuple[List[str], List[str]]:
        """ä½¿ç”¨GPTæå–å®ä½“å’Œæ¦‚å¿µ"""
        try:
            prompt = f"""
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®å®ä½“å’Œæ¦‚å¿µï¼š

æ–‡æœ¬: {content}

è¯·æå–ï¼š
1. å®ä½“ï¼šäººåã€åœ°åã€ç‰©å“åã€å…·ä½“äº‹ç‰©
2. æ¦‚å¿µï¼šæŠ½è±¡æ¦‚å¿µã€å…³ç³»ã€å±æ€§ã€çŠ¶æ€

è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "entities": ["å®ä½“1", "å®ä½“2"],
    "concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"]
}}

ç¤ºä¾‹ï¼š
æ–‡æœ¬: "æ˜Ÿæ˜Ÿæ˜¯æˆ‘çš„å¼Ÿå¼Ÿ"
è¾“å‡º: {{"entities": ["æ˜Ÿæ˜Ÿ"], "concepts": ["å¼Ÿå¼Ÿ", "å®¶åº­å…³ç³»"]}}

æ–‡æœ¬: "æˆ‘ä½åœ¨åŒ—äº¬"
è¾“å‡º: {{"entities": ["åŒ—äº¬"], "concepts": ["å±…ä½åœ°", "åœ°ç†ä½ç½®"]}}
"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.1
            )
            
            if response.choices:
                result_text = response.choices[0].message.content.strip()
                try:
                    result_data = json.loads(result_text)
                    entities = result_data.get("entities", [])
                    concepts = result_data.get("concepts", [])
                    return entities, concepts
                except json.JSONDecodeError:
                    logger.warning("GPTå®ä½“æå–JSONè§£æå¤±è´¥")
                    return self._fallback_entity_extraction(content)
            
            return self._fallback_entity_extraction(content)
            
        except Exception as e:
            logger.error(f"GPTå®ä½“æå–å¤±è´¥: {e}")
            return self._fallback_entity_extraction(content)
    
    def _fallback_entity_extraction(self, content: str) -> Tuple[List[str], List[str]]:
        """å¤‡ç”¨å®ä½“æå–"""
        import re
        
        entities = []
        concepts = []
        
        # ç®€å•çš„å®ä½“è¯†åˆ«
        # äººåè¯†åˆ«ï¼ˆä¸­æ–‡å§“åï¼‰
        name_matches = re.findall(r'[æ˜Ÿæœˆå…‰æ˜äº®å¼ºä¼Ÿåå»ºå†›å›½åº†][æ˜Ÿæœˆå…‰æ˜äº®å¼ºä¼Ÿåå»ºå†›å›½åº†]?', content)
        entities.extend(name_matches)
        
        # åœ°åè¯†åˆ«
        location_keywords = ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³', 'å¹¿å·', 'æ­å·', 'æˆéƒ½', 'é‡åº†', 'æ­¦æ±‰', 'è¥¿å®‰', 'å—äº¬']
        for location in location_keywords:
            if location in content:
                entities.append(location)
        
        # æ¦‚å¿µè¯†åˆ«
        if 'å¼Ÿå¼Ÿ' in content or 'å“¥å“¥' in content or 'å§å§' in content or 'å¦¹å¦¹' in content:
            concepts.append('å®¶åº­å…³ç³»')
        
        if 'å–œæ¬¢' in content or 'çˆ±å¥½' in content:
            concepts.append('åå¥½')
        
        if 'å·¥ä½œ' in content or 'èŒä¸š' in content:
            concepts.append('èŒä¸š')
        
        if 'ä½' in content or 'å®¶' in content:
            concepts.append('å±…ä½')
        
        return entities, concepts
    
    async def _store_memory_node(self, node: MemoryNode):
        """å­˜å‚¨è®°å¿†èŠ‚ç‚¹"""
        try:
            self.conn.execute("""
                INSERT OR REPLACE INTO memory_nodes 
                (id, content, memory_type, importance, entities, concepts, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                node.id,
                node.content,
                node.memory_type,
                node.importance,
                json.dumps(node.entities),
                json.dumps(node.concepts),
                node.timestamp
            ))
            
            # åŒæ—¶æ›´æ–°å®ä½“ç´¢å¼•
            for entity in node.entities:
                self.conn.execute("""
                    INSERT OR REPLACE INTO entity_index 
                    (entity, memory_id, entity_type, confidence)
                    VALUES (?, ?, ?, ?)
                """, (entity, node.id, "entity", 1.0))
            
            self.conn.commit()
            
        except Exception as e:
            logger.error(f"å­˜å‚¨è®°å¿†èŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _build_relations_for_new_memory(self, new_node: MemoryNode):
        """ä¸ºæ–°è®°å¿†æ„å»ºä¸ç°æœ‰è®°å¿†çš„å…³è”"""
        try:
            # è·å–æ‰€æœ‰ç°æœ‰è®°å¿†èŠ‚ç‚¹
            cursor = self.conn.execute("""
                SELECT id, content, memory_type, entities, concepts 
                FROM memory_nodes WHERE id != ?
            """, (new_node.id,))
            
            existing_nodes = []
            for row in cursor.fetchall():
                node = MemoryNode(
                    id=row[0],
                    content=row[1],
                    memory_type=row[2],
                    importance=0,  # æš‚æ—¶ä¸éœ€è¦
                    entities=json.loads(row[3]) if row[3] else [],
                    concepts=json.loads(row[4]) if row[4] else [],
                    timestamp=0  # æš‚æ—¶ä¸éœ€è¦
                )
                existing_nodes.append(node)
            
            # åˆ†æå…³è”å…³ç³»
            for existing_node in existing_nodes:
                relations = await self._analyze_relation_between_memories(new_node, existing_node)
                
                for relation in relations:
                    if relation.confidence >= self.relation_confidence_threshold:
                        await self._store_memory_edge(relation)
            
        except Exception as e:
            logger.error(f"æ„å»ºè®°å¿†å…³è”å¤±è´¥: {e}")
    
    async def _analyze_relation_between_memories(self, memory1: MemoryNode, 
                                               memory2: MemoryNode) -> List[MemoryEdge]:
        """åˆ†æä¸¤ä¸ªè®°å¿†ä¹‹é—´çš„å…³è”å…³ç³»"""
        try:
            relations = []
            
            # 1. å®ä½“å…³è”æ£€æµ‹
            common_entities = set(memory1.entities) & set(memory2.entities)
            if common_entities:
                for entity in common_entities:
                    relation = await self._create_entity_relation(memory1, memory2, entity)
                    if relation:
                        relations.append(relation)
            
            # 2. æ¦‚å¿µå…³è”æ£€æµ‹
            common_concepts = set(memory1.concepts) & set(memory2.concepts)
            if common_concepts:
                for concept in common_concepts:
                    relation = await self._create_concept_relation(memory1, memory2, concept)
                    if relation:
                        relations.append(relation)
            
            # 3. è¯­ä¹‰å…³è”æ£€æµ‹ï¼ˆä½¿ç”¨GPTï¼‰
            if not relations:  # å¦‚æœæ²¡æœ‰ç›´æ¥å…³è”ï¼Œå°è¯•è¯­ä¹‰å…³è”
                semantic_relation = await self._analyze_semantic_relation(memory1, memory2)
                if semantic_relation:
                    relations.append(semantic_relation)
            
            return relations
            
        except Exception as e:
            logger.error(f"åˆ†æè®°å¿†å…³è”å¤±è´¥: {e}")
            return []
    
    async def _create_entity_relation(self, memory1: MemoryNode, memory2: MemoryNode, 
                                    entity: str) -> Optional[MemoryEdge]:
        """åˆ›å»ºå®ä½“å…³è”"""
        try:
            # åˆ¤æ–­å…³è”ç±»å‹
            relation_type = RelationType.IDENTITY
            confidence = 0.9
            description = f"éƒ½æåˆ°äº†å®ä½“: {entity}"
            
            # æ ¹æ®è®°å¿†ç±»å‹ä¼˜åŒ–å…³è”ç±»å‹
            if memory1.memory_type == "family" or memory2.memory_type == "family":
                relation_type = RelationType.FAMILY
                description = f"å®¶åº­ç›¸å…³å®ä½“: {entity}"
            elif memory1.memory_type == "work" or memory2.memory_type == "work":
                relation_type = RelationType.WORK
                description = f"å·¥ä½œç›¸å…³å®ä½“: {entity}"
            
            edge_id = f"{memory1.id}_{memory2.id}_{entity}"
            
            return MemoryEdge(
                id=edge_id,
                source_memory_id=memory1.id,
                target_memory_id=memory2.id,
                relation_type=relation_type,
                confidence=confidence,
                description=description,
                timestamp=time.time()
            )
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå®ä½“å…³è”å¤±è´¥: {e}")
            return None
    
    async def _create_concept_relation(self, memory1: MemoryNode, memory2: MemoryNode, 
                                     concept: str) -> Optional[MemoryEdge]:
        """åˆ›å»ºæ¦‚å¿µå…³è”"""
        try:
            relation_type = RelationType.SEMANTIC
            confidence = 0.8
            description = f"å…±åŒæ¦‚å¿µ: {concept}"
            
            # ç‰¹å®šæ¦‚å¿µçš„å…³è”ç±»å‹
            if concept == "å®¶åº­å…³ç³»":
                relation_type = RelationType.FAMILY
            elif concept == "èŒä¸š":
                relation_type = RelationType.WORK
            elif concept == "åå¥½":
                relation_type = RelationType.PREFERENCE
            
            edge_id = f"{memory1.id}_{memory2.id}_{concept}"
            
            return MemoryEdge(
                id=edge_id,
                source_memory_id=memory1.id,
                target_memory_id=memory2.id,
                relation_type=relation_type,
                confidence=confidence,
                description=description,
                timestamp=time.time()
            )
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ¦‚å¿µå…³è”å¤±è´¥: {e}")
            return None
    
    async def _analyze_semantic_relation(self, memory1: MemoryNode, 
                                   memory2: MemoryNode) -> Optional[MemoryEdge]:
        """ä½¿ç”¨GPTåˆ†æè¯­ä¹‰å…³è” - ä¿®å¤ç‰ˆ"""
        try:
            prompt = f"""
    åˆ†æä»¥ä¸‹ä¸¤æ®µè®°å¿†æ˜¯å¦å­˜åœ¨è¯­ä¹‰å…³è”ï¼š

    è®°å¿†1: {memory1.content}
    è®°å¿†2: {memory2.content}

    è¯·åˆ¤æ–­å®ƒä»¬ä¹‹é—´æ˜¯å¦å­˜åœ¨å…³è”ï¼Œå¦‚æœå­˜åœ¨ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å…³è”ç±»å‹ã€‚

    è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡ºï¼š
    {{
        "has_relation": true,
        "relation_type": "family",
        "confidence": 0.8,
        "description": "å…³è”æè¿°"
    }}

    æˆ–è€…ï¼š
    {{
        "has_relation": false
    }}

    å…³è”ç±»å‹åªèƒ½æ˜¯ï¼šidentity, family, location, skill, preference, work, physical, causal, semantic
    """

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.1
            )
            
            if response.choices:
                result_text = response.choices[0].message.content.strip()
                
                # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
                if "```json" in result_text:
                    result_text = result_text.split("```json")[1].split("```")[0].strip()
                elif "```" in result_text:
                    result_text = result_text.split("```")[1].strip()
                
                try:
                    result_data = json.loads(result_text)
                    
                    if result_data.get("has_relation", False):
                        relation_type = result_data.get("relation_type", "semantic")
                        
                        # éªŒè¯å…³è”ç±»å‹
                        valid_types = [rt.value for rt in RelationType]
                        if relation_type not in valid_types:
                            relation_type = "semantic"
                        
                        edge_id = f"{memory1.id}_{memory2.id}_semantic"
                        
                        return MemoryEdge(
                            id=edge_id,
                            source_memory_id=memory1.id,
                            target_memory_id=memory2.id,
                            relation_type=RelationType(relation_type),
                            confidence=min(result_data.get("confidence", 0.5), 1.0),
                            description=result_data.get("description", "è¯­ä¹‰å…³è”"),
                            timestamp=time.time()
                        )
                except json.JSONDecodeError as e:
                    logger.debug(f"è¯­ä¹‰å…³è”åˆ†æJSONè§£æå¤±è´¥: {result_text[:100]}...")
                    return None
            
            return None
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰å…³è”åˆ†æå¤±è´¥: {e}")
            return None
    async def enhanced_graph_search(self, question: str, primary_memories: List[Any]) -> Tuple[str, List[str]]:
        """å¢å¼ºå›¾è°±æœç´¢ - å¤šå±‚å…³è”"""
        try:
            logger.info(f"ğŸ•¸ï¸ å¢å¼ºå›¾è°±æœç´¢: {question}")
            
            # 1. ä»é—®é¢˜ä¸­æå–å®ä½“
            question_entities, question_concepts = await self._extract_entities_and_concepts(question)
            logger.debug(f"é—®é¢˜å®ä½“: {question_entities}, æ¦‚å¿µ: {question_concepts}")
            
            # 2. ç›´æ¥å®ä½“æœç´¢
            entity_memories = []
            for entity in question_entities:
                cursor = self.conn.execute("""
                    SELECT memory_id FROM entity_index WHERE entity = ?
                """, (entity,))
                
                for row in cursor.fetchall():
                    memory = await self._get_memory_node_by_id(row[0])
                    if memory and memory not in entity_memories:
                        entity_memories.append(memory)
            
            # 3. è·å–æ‰€æœ‰ç›¸å…³è®°å¿†
            all_related_memories = []
            all_relations = []
            
            # ä»ä¸»è¦è®°å¿†å‡ºå‘
            for memory in primary_memories:
                related_memories, relations = await self._get_related_memories(memory.id)
                all_related_memories.extend(related_memories)
                all_relations.extend(relations)
            
            # ä»å®ä½“è®°å¿†å‡ºå‘
            for memory in entity_memories:
                related_memories, relations = await self._get_related_memories(memory.id)
                all_related_memories.extend(related_memories)
                all_relations.extend(relations)
            
            # å»é‡
            all_memories = list(set(primary_memories + entity_memories + all_related_memories))
            
            # 4. æ„å»ºå¢å¼ºæ¨ç†é“¾
            inference_chain = await self._build_enhanced_inference_chain(
                question, question_entities, all_memories, all_relations
            )
            
            # 5. ç”Ÿæˆå›ç­”
            response = await self._generate_enhanced_response(question, all_memories, inference_chain)
            
            used_memory_ids = [m.id for m in all_memories]
            
            logger.info(f"âœ… å¢å¼ºå›¾è°±å›ç­”: {response}")
            return response, used_memory_ids
            
        except Exception as e:
            logger.error(f"å¢å¼ºå›¾è°±æœç´¢å¤±è´¥: {e}")
            return "", []

    async def _get_memory_node_by_id(self, memory_id: str) -> Optional[MemoryNode]:
        """æ ¹æ®IDè·å–è®°å¿†èŠ‚ç‚¹"""
        try:
            cursor = self.conn.execute("""
                SELECT content, memory_type, importance, entities, concepts, timestamp
                FROM memory_nodes WHERE id = ?
            """, (memory_id,))
            
            result = cursor.fetchone()
            if result:
                return MemoryNode(
                    id=memory_id,
                    content=result[0],
                    memory_type=result[1],
                    importance=result[2],
                    entities=json.loads(result[3]) if result[3] else [],
                    concepts=json.loads(result[4]) if result[4] else [],
                    timestamp=result[5]
                )
            
            return None
            
        except Exception as e:
            logger.error(f"è·å–è®°å¿†èŠ‚ç‚¹å¤±è´¥: {e}")
            return None

    async def _build_enhanced_inference_chain(self, question: str, question_entities: List[str],
                                            memories: List[MemoryNode], 
                                            relations: List[MemoryEdge]) -> List[str]:
        """æ„å»ºå¢å¼ºæ¨ç†é“¾"""
        try:
            inference_chain = []
            
            # å®ä½“æ¨ç†
            for entity in question_entities:
                entity_memories = [m for m in memories if entity in m.entities]
                if entity_memories:
                    inference_chain.append(f"å®ä½“'{entity}'ç›¸å…³è®°å¿†:")
                    for memory in entity_memories[:3]:  # æœ€å¤š3æ¡
                        inference_chain.append(f"  - {memory.content}")
            
            # å…³è”æ¨ç†
            high_confidence_relations = [r for r in relations if r.confidence > 0.8]
            if high_confidence_relations:
                inference_chain.append("é«˜ç½®ä¿¡åº¦å…³è”:")
                for relation in high_confidence_relations[:3]:
                    inference_chain.append(f"  - {relation.description}")
            
            return inference_chain
            
        except Exception as e:
            logger.error(f"æ„å»ºæ¨ç†é“¾å¤±è´¥: {e}")
            return []

    async def _generate_enhanced_response(self, question: str, memories: List[MemoryNode], 
                                        inference_chain: List[str]) -> str:
        """ç”Ÿæˆå¢å¼ºå›ç­”"""
        try:
            # æ„å»ºæ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
            memory_context = []
            
            # æŒ‰é‡è¦æ€§æ’åº
            sorted_memories = sorted(memories, key=lambda x: x.importance, reverse=True)
            
            for memory in sorted_memories[:10]:  # æœ€å¤š10æ¡è®°å¿†
                memory_context.append(f"- {memory.content} (é‡è¦æ€§: {memory.importance:.2f})")
            
            context = "\n".join(memory_context)
            inference_text = "\n".join(inference_chain) if inference_chain else "æ— ç‰¹æ®Šæ¨ç†"
            
            prompt = f"""åŸºäºä»¥ä¸‹è®°å¿†ä¿¡æ¯å’Œæ¨ç†é“¾ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

    é—®é¢˜: {question}

    è®°å¿†ä¿¡æ¯:
    {context}

    æ¨ç†é“¾:
    {inference_text}

    è¦æ±‚:
    1. ä¼˜å…ˆä½¿ç”¨æ¨ç†é“¾ä¸­çš„ä¿¡æ¯
    2. å¦‚æœèƒ½æ‰¾åˆ°ç­”æ¡ˆï¼Œç›´æ¥å›ç­”
    3. å¦‚æœéœ€è¦æ¨ç†ï¼Œè¯´æ˜æ¨ç†è¿‡ç¨‹
    4. å¦‚æœç¡®å®æ²¡æœ‰ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜ç¼ºå°‘ä»€ä¹ˆ
    5. 1-2å¥è¯ç®€æ´å›ç­”

    è¯·ç›´æ¥ç»™å‡ºå›ç­”ï¼š"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.7
            )
            
            if response.choices:
                return response.choices[0].message.content.strip()
            
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åŸºäºç°æœ‰ä¿¡æ¯å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¢å¼ºå›ç­”å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    async def _store_memory_edge(self, edge: MemoryEdge):
        """å­˜å‚¨è®°å¿†å…³è”"""
        try:
            self.conn.execute("""
                INSERT OR REPLACE INTO memory_edges 
                (id, source_memory_id, target_memory_id, relation_type, confidence, description, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                edge.id,
                edge.source_memory_id,
                edge.target_memory_id,
                edge.relation_type.value,
                edge.confidence,
                edge.description,
                edge.timestamp
            ))
            
            self.conn.commit()
            logger.debug(f"âœ… å­˜å‚¨å…³è”: {edge.description}")
            
        except Exception as e:
            logger.error(f"å­˜å‚¨è®°å¿†å…³è”å¤±è´¥: {e}")
    
    async def graph_search_and_respond(self, question: str, 
                                     primary_memories: List[Any]) -> Tuple[str, List[str]]:
        """åŸºäºå›¾è°±æœç´¢å¹¶ç”Ÿæˆå…³è”å›ç­”"""
        try:
            logger.info(f"ğŸ•¸ï¸ å›¾è°±æœç´¢é—®é¢˜: {question}")
            # é¦–å…ˆå°è¯•å¢å¼ºæœç´¢
            enhanced_response, enhanced_memory_ids = await self.enhanced_graph_search(question, primary_memories)
            
            if enhanced_response and "æŠ±æ­‰" not in enhanced_response:
                return enhanced_response, enhanced_memory_ids
            # 1. è·å–ä¸»è¦è®°å¿†çš„ç›¸å…³è®°å¿†
            all_related_memories = []
            all_relations = []
            
            for memory in primary_memories:
                related_memories, relations = await self._get_related_memories(memory.id)
                all_related_memories.extend(related_memories)
                all_relations.extend(relations)
            
            # 2. æ„å»ºæ¨ç†é“¾
            inference_chain = await self._build_inference_chain(question, primary_memories, all_related_memories, all_relations)
            
            # 3. ç”Ÿæˆå…³è”å›ç­”
            response = await self._generate_graph_response(question, primary_memories, all_related_memories, inference_chain)
            
            # 4. æ”¶é›†ä½¿ç”¨çš„è®°å¿†ID
            used_memory_ids = [m.id for m in primary_memories] + [m.id for m in all_related_memories]
            
            logger.info(f"âœ… å›¾è°±å›ç­”ç”Ÿæˆ: {response}")
            return response, used_memory_ids
            
        except Exception as e:
            logger.error(f"å›¾è°±æœç´¢å›ç­”å¤±è´¥: {e}")
            return "", []
    
    async def _get_related_memories(self, memory_id: str) -> Tuple[List[MemoryNode], List[MemoryEdge]]:
        """è·å–ç›¸å…³è®°å¿† - å¢å¼ºç‰ˆ"""
        try:
            # 1. è·å–ç›®æ ‡è®°å¿†çš„å®ä½“å’Œæ¦‚å¿µ
            cursor = self.conn.execute("""
                SELECT entities, concepts FROM memory_nodes WHERE id = ?
            """, (memory_id,))
            
            result = cursor.fetchone()
            if not result:
                return [], []
            
            target_entities = json.loads(result[0]) if result[0] else []
            target_concepts = json.loads(result[1]) if result[1] else []
            
            # 2. æŸ¥æ‰¾ç›´æ¥å…³è”çš„è®°å¿†
            cursor = self.conn.execute("""
                SELECT e.target_memory_id, e.relation_type, e.confidence, e.description,
                    n.content, n.memory_type, n.importance, n.entities, n.concepts
                FROM memory_edges e
                JOIN memory_nodes n ON e.target_memory_id = n.id
                WHERE e.source_memory_id = ?
                UNION
                SELECT e.source_memory_id, e.relation_type, e.confidence, e.description,
                    n.content, n.memory_type, n.importance, n.entities, n.concepts
                FROM memory_edges e
                JOIN memory_nodes n ON e.source_memory_id = n.id
                WHERE e.target_memory_id = ?
                ORDER BY e.confidence DESC
            """, (memory_id, memory_id))
            
            related_memories = []
            relations = []
            found_memory_ids = set()
            
            for row in cursor.fetchall():
                related_memory = MemoryNode(
                    id=row[0],
                    content=row[4],
                    memory_type=row[5],
                    importance=row[6],
                    entities=json.loads(row[7]) if row[7] else [],
                    concepts=json.loads(row[8]) if row[8] else [],
                    timestamp=0
                )
                related_memories.append(related_memory)
                found_memory_ids.add(row[0])
                
                relation = MemoryEdge(
                    id="",
                    source_memory_id=memory_id,
                    target_memory_id=row[0],
                    relation_type=RelationType(row[1]),
                    confidence=row[2],
                    description=row[3],
                    timestamp=0
                )
                relations.append(relation)
            
            # 3. æŸ¥æ‰¾å®ä½“å…³è”çš„è®°å¿†ï¼ˆæ–°å¢ï¼‰
            if target_entities:
                for entity in target_entities:
                    cursor = self.conn.execute("""
                        SELECT memory_id FROM entity_index 
                        WHERE entity = ? AND memory_id != ?
                    """, (entity, memory_id))
                    
                    for entity_row in cursor.fetchall():
                        entity_memory_id = entity_row[0]
                        if entity_memory_id not in found_memory_ids:
                            # è·å–è¿™ä¸ªè®°å¿†çš„è¯¦ç»†ä¿¡æ¯
                            memory_cursor = self.conn.execute("""
                                SELECT content, memory_type, importance, entities, concepts
                                FROM memory_nodes WHERE id = ?
                            """, (entity_memory_id,))
                            
                            memory_result = memory_cursor.fetchone()
                            if memory_result:
                                related_memory = MemoryNode(
                                    id=entity_memory_id,
                                    content=memory_result[0],
                                    memory_type=memory_result[1],
                                    importance=memory_result[2],
                                    entities=json.loads(memory_result[3]) if memory_result[3] else [],
                                    concepts=json.loads(memory_result[4]) if memory_result[4] else [],
                                    timestamp=0
                                )
                                related_memories.append(related_memory)
                                found_memory_ids.add(entity_memory_id)
                                
                                # åˆ›å»ºå®ä½“å…³è”
                                relation = MemoryEdge(
                                    id="",
                                    source_memory_id=memory_id,
                                    target_memory_id=entity_memory_id,
                                    relation_type=RelationType.IDENTITY,
                                    confidence=0.9,
                                    description=f"å…±åŒå®ä½“: {entity}",
                                    timestamp=0
                                )
                                relations.append(relation)
            
            return related_memories, relations
            
        except Exception as e:
            logger.error(f"è·å–ç›¸å…³è®°å¿†å¤±è´¥: {e}")
            return [], []
    
    async def _build_inference_chain(self, question: str, primary_memories: List[Any], 
                                   related_memories: List[MemoryNode], 
                                   relations: List[MemoryEdge]) -> List[str]:
        """æ„å»ºæ¨ç†é“¾"""
        try:
            inference_chain = []
            
            # ç®€å•çš„æ¨ç†é“¾æ„å»º
            for primary in primary_memories:
                inference_chain.append(f"å·²çŸ¥: {primary.content}")
            
            for relation in relations:
                if relation.confidence > 0.8:
                    inference_chain.append(f"å…³è”: {relation.description}")
            
            for related in related_memories:
                inference_chain.append(f"ç›¸å…³: {related.content}")
            
            return inference_chain
            
        except Exception as e:
            logger.error(f"æ„å»ºæ¨ç†é“¾å¤±è´¥: {e}")
            return []
    
    async def _generate_graph_response(self, question: str, primary_memories: List[Any],
                                     related_memories: List[MemoryNode], 
                                     inference_chain: List[str]) -> str:
        """ç”ŸæˆåŸºäºå›¾è°±çš„å…³è”å›ç­”"""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            
            # ä¸»è¦è®°å¿†
            context_parts.append("ç›´æ¥ç›¸å…³è®°å¿†:")
            for memory in primary_memories:
                context_parts.append(f"- {memory.content}")
            
            # ç›¸å…³è®°å¿†
            if related_memories:
                context_parts.append("\nå…³è”è®°å¿†:")
                for memory in related_memories[:3]:  # æœ€å¤š3æ¡ç›¸å…³è®°å¿†
                    context_parts.append(f"- {memory.content}")
            
            # æ¨ç†é“¾
            if inference_chain:
                context_parts.append("\næ¨ç†é“¾:")
                for step in inference_chain[:5]:  # æœ€å¤š5æ­¥æ¨ç†
                    context_parts.append(f"â†’ {step}")
            
            context = "\n".join(context_parts)
            
            prompt = f"""åŸºäºä»¥ä¸‹è®°å¿†å›¾è°±ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚è¯·åˆ©ç”¨è®°å¿†ä¹‹é—´çš„å…³è”å…³ç³»è¿›è¡Œæ¨ç†ã€‚

é—®é¢˜: {question}

è®°å¿†å›¾è°±ä¿¡æ¯:
{context}

è¦æ±‚:
1. åŸºäºç°æœ‰è®°å¿†è¿›è¡Œå…³è”æ¨ç†
2. å¦‚æœèƒ½é€šè¿‡å…³è”æ¨æ–­å‡ºç­”æ¡ˆï¼Œè¯·ç»™å‡ºæ¨ç†è¿‡ç¨‹
3. å¦‚æœç¡®å®ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼Œæ˜ç¡®æŒ‡å‡ºç¼ºå°‘ä»€ä¹ˆ
4. 1-2å¥è¯ç®€æ´å›ç­”
5. ç”¨ç¬¬ä¸€äººç§°å›ç­”

è¯·ç›´æ¥ç»™å‡ºå›ç­”ï¼š"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.7
            )
            
            if response.choices:
                return response.choices[0].message.content.strip()
            
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åŸºäºç°æœ‰ä¿¡æ¯å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾è°±å›ç­”å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
    
    async def get_graph_statistics(self) -> Dict[str, Any]:
        """è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # èŠ‚ç‚¹ç»Ÿè®¡
            cursor = self.conn.execute("SELECT COUNT(*) FROM memory_nodes")
            node_count = cursor.fetchone()[0]
            
            # è¾¹ç»Ÿè®¡
            cursor = self.conn.execute("SELECT COUNT(*) FROM memory_edges")
            edge_count = cursor.fetchone()[0]
            
            # å…³è”ç±»å‹ç»Ÿè®¡
            cursor = self.conn.execute("""
                SELECT relation_type, COUNT(*) 
                FROM memory_edges 
                GROUP BY relation_type
                ORDER BY COUNT(*) DESC
            """)
            relation_types = dict(cursor.fetchall())
            
            # å®ä½“ç»Ÿè®¡
            cursor = self.conn.execute("SELECT COUNT(DISTINCT entity) FROM entity_index")
            entity_count = cursor.fetchone()[0]
            
            return {
                "node_count": node_count,
                "edge_count": edge_count,
                "entity_count": entity_count,
                "relation_types": relation_types,
                "graph_density": edge_count / max(node_count * (node_count - 1), 1)
            }
            
        except Exception as e:
            logger.error(f"è·å–å›¾è°±ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}