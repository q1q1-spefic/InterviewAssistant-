#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆä¼˜åŒ–è¯­éŸ³å¢å¼ºå™¨ - é›†æˆOpenAIé«˜çº§è®°å¿†ç³»ç»Ÿ
"""
import asyncio
import signal
import sys
import time
import subprocess
import threading
import uuid
import re
import os
import aiohttp
import json
from queue import Queue
from loguru import logger
from config import config
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Tuple
from enum import Enum

class FixedTTSEngine:
    """ä¿®å¤çš„TTSå¼•æ“"""
    
    def __init__(self):
        self.audio_buffer = asyncio.Queue(maxsize=20)  # å‡å°ç¼“å†²åŒº
        self.tts_semaphore = asyncio.Semaphore(3)  # å¢åŠ åˆ°3ä¸ªå¹¶å‘
        self.running = True
        self.session_players = {}  # æ¯ä¸ªä¼šè¯çš„æ’­æ”¾å™¨
        logger.info("ğŸ”Š ä¿®å¤TTSå¼•æ“åˆå§‹åŒ–")
    
    async def start_engine(self):
        """å¯åŠ¨TTSå¼•æ“"""
        asyncio.create_task(self._audio_player())
        logger.info("âœ… ä¿®å¤TTSå¼•æ“å·²å¯åŠ¨")
    
    async def speak_streaming(self, text, session_id=None):
        """ä¿®å¤çš„æµå¼è¯­éŸ³åˆæˆ"""
        try:
            if not self.running or not text.strip():
                return
                
            if not session_id:
                session_id = str(uuid.uuid4())[:8]
            
            # æ›´ç®€å•çš„åˆ†å¥ç­–ç•¥
            sentences = self._simple_split_sentences(text)
            if not sentences:
                return
                
            logger.info(f"ğŸµ å¼€å§‹TTS[{session_id}]: {len(sentences)}å¥")
            
            # é¡ºåºå¤„ç†ï¼Œé¿å…å¹¶å‘é—®é¢˜
            for i, sentence in enumerate(sentences):
                if not self.running:
                    break
                    
                try:
                    await self._process_single_sentence(sentence, session_id, i)
                except Exception as e:
                    logger.error(f"å¤„ç†å¥å­å¤±è´¥[{session_id}-{i}]: {e}")
                    continue
            
            logger.info(f"âœ… TTSå®Œæˆ[{session_id}]")
            
        except Exception as e:
            logger.error(f"æµå¼TTSå¤±è´¥: {e}")
            logger.info(f"ğŸ“ æ–‡å­—å›ç­”: {text}")
    
    def _simple_split_sentences(self, text):
        """ç®€åŒ–çš„åˆ†å¥ç­–ç•¥"""
        if not text.strip():
            return []
        
        # åŸºæœ¬çš„å¥å­åˆ†å‰²
        sentences = []
        current = ""
        
        for char in text:
            current += char
            if char in ['ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?'] and len(current.strip()) > 3:
                sentences.append(current.strip())
                current = ""
            elif char in ['ï¼Œ', ','] and len(current.strip()) > 20:
                sentences.append(current.strip())
                current = ""
        
        # æ·»åŠ å‰©ä½™éƒ¨åˆ†
        if current.strip() and len(current.strip()) > 3:
            sentences.append(current.strip())
        
        return sentences
    
    async def _process_single_sentence(self, sentence, session_id, index):
        """å¤„ç†å•ä¸ªå¥å­"""
        async with self.tts_semaphore:
            try:
                task_id = f"{session_id}-{index}"
                logger.debug(f"ğŸ”Š TTS[{task_id}]: {sentence}")
                
                # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
                audio_file = await self._generate_audio_file(sentence)
                if not audio_file or not self.running:
                    return
                
                # ç«‹å³æ’­æ”¾
                await self._play_audio_immediately(audio_file, task_id, sentence)
                
            except Exception as e:
                logger.error(f"å¤„ç†å¥å­å¤±è´¥: {e}")
    
    async def _generate_audio_file(self, text):
        """ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        try:
            import edge_tts
            import tempfile
            
            # ä½¿ç”¨æ›´ç¨³å®šçš„è¯­éŸ³
            communicate = edge_tts.Communicate(
                text, 
                "zh-CN-XiaoxiaoNeural",  # ä½¿ç”¨æ›´ç¨³å®šçš„å£°éŸ³
                rate="+20%"  # å‡å°‘è¯­é€Ÿè°ƒæ•´
            )
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            temp_file.close()
            
            # ç”ŸæˆéŸ³é¢‘ï¼Œæ·»åŠ è¶…æ—¶
            await asyncio.wait_for(
                communicate.save(temp_file.name),
                timeout=10.0  # 10ç§’è¶…æ—¶
            )
            
            return temp_file.name
            
        except asyncio.TimeoutError:
            logger.warning(f"TTSç”Ÿæˆè¶…æ—¶: {text}")
            return None
        except Exception as e:
            logger.error(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥: {e}")
            return None
    
    async def _play_audio_immediately(self, audio_file, task_id, text):
        """ç«‹å³æ’­æ”¾éŸ³é¢‘"""
        try:
            if not self.running:
                return
                
            logger.info(f"ğŸµ æ’­æ”¾[{task_id}]: {text}")
            
            if sys.platform == "darwin":  # macOS
                # ä½¿ç”¨å¼‚æ­¥å­è¿›ç¨‹
                process = await asyncio.create_subprocess_exec(
                    "afplay", audio_file,
                    stdout=asyncio.subprocess.DEVNULL,
                    stderr=asyncio.subprocess.DEVNULL
                )
                
                try:
                    # ç­‰å¾…æ’­æ”¾å®Œæˆï¼Œä½†è®¾ç½®è¶…æ—¶
                    await asyncio.wait_for(process.wait(), timeout=15.0)
                    logger.debug(f"âœ… æ’­æ”¾å®Œæˆ[{task_id}]")
                except asyncio.TimeoutError:
                    process.terminate()
                    logger.warning(f"â° æ’­æ”¾è¶…æ—¶[{task_id}]")
            else:
                logger.info(f"ğŸ’¾ éŸ³é¢‘æ–‡ä»¶: {audio_file}")
            
            # å»¶è¿Ÿåˆ é™¤æ–‡ä»¶
            asyncio.create_task(self._cleanup_audio_file(audio_file))
            
        except Exception as e:
            logger.error(f"æ’­æ”¾éŸ³é¢‘å¤±è´¥[{task_id}]: {e}")
    
    async def _audio_player(self):
        """ç®€åŒ–çš„éŸ³é¢‘æ’­æ”¾å™¨ï¼ˆå¤‡ç”¨ï¼‰"""
        while self.running:
            await asyncio.sleep(1)  # åŸºæœ¬çš„ä¿æ´»å¾ªç¯
    
    async def _cleanup_audio_file(self, file_path):
        """æ¸…ç†éŸ³é¢‘æ–‡ä»¶"""
        try:
            await asyncio.sleep(2)  # ç­‰å¾…æ’­æ”¾å®Œæˆ
            if os.path.exists(file_path):
                os.unlink(file_path)
        except Exception as e:
            logger.debug(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")
    
    async def stop(self):
        """åœæ­¢TTSå¼•æ“"""
        logger.info("ğŸ›‘ åœæ­¢TTSå¼•æ“...")
        self.running = False

class FixedVoiceEnhancer:
    """ä¿®å¤ç‰ˆè¯­éŸ³å¢å¼ºå™¨ - é›†æˆOpenAIè®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.running = False
        self.recognizer = None
        self.openai_client = None
        
        # ä¿®å¤çš„TTSå¼•æ“
        self.tts_engine = FixedTTSEngine()
        
        # ç®€åŒ–çš„é˜Ÿåˆ—ç³»ç»Ÿ
        self.partial_text_queue = Queue(maxsize=20)
        self.final_text_queue = Queue(maxsize=10)
        self.response_queue = asyncio.Queue(maxsize=5)
        
        # å¹¶å‘æ§åˆ¶
        self.response_semaphore = asyncio.Semaphore(2)
        self.active_responses = {}
        
        # ä¿®å¤çš„æ€è€ƒç³»ç»Ÿ
        self.thinking_tasks = {}
        self.partial_thoughts = {}
        self.last_thinking_time = {}
        self.thinking_cooldown = 1.0  # å¢åŠ å†·å´æ—¶é—´
        
        # å¯¹è¯çŠ¶æ€
        self.speech_segments = []
        self.last_speech_time = 0
        self.silence_threshold = 2.0  # å¢åŠ é™éŸ³é˜ˆå€¼
        
        # === æ–°å¢ï¼šOpenAIè®°å¿†ç³»ç»Ÿ ===
        self.openai_memory_manager = None
        self.memory_enabled = True
        
        logger.info("ğŸš€ ä¿®å¤ç‰ˆè¯­éŸ³å¢å¼ºå™¨åˆå§‹åŒ– (æ”¯æŒOpenAIè®°å¿†)")
    
    async def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        logger.info("ğŸš€ å¯åŠ¨ä¿®å¤ç‰ˆè¯­éŸ³å¢å¼ºå™¨...")
        
        try:
            await self._init_speech_recognition()
            await self._init_openai()
            await self._init_openai_memory()
            await self.tts_engine.start_engine()
            
            self.running = True
            logger.info("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸï¼")
            logger.info("")
            logger.info("ğŸ¤ = = = OpenAIè®°å¿†ç‰ˆåŠŸèƒ½ = = =")
            logger.info("ğŸ§  OpenAIæ™ºèƒ½è®°å¿†ç³»ç»Ÿ")
            logger.info("ğŸ” å‘é‡ç›¸ä¼¼åº¦æœç´¢")
            logger.info("âš¡ GPTæ™ºèƒ½ä¿¡æ¯æå–")
            logger.info("ğŸ¯ æ™ºèƒ½å†²çªè§£å†³")
            logger.info("ğŸ’¬ ä¸ªæ€§åŒ–å›ç­”ç”Ÿæˆ")
            logger.info("âŒ¨ï¸  æŒ‰ Ctrl+C é€€å‡º")
            logger.info("= = = = = = = = = = = = =")
            logger.info("")
            
            # å¯åŠ¨å¤„ç†ä»»åŠ¡
            self.processing_tasks = []
            self.processing_tasks.append(asyncio.create_task(self._partial_text_processor(), name="partial"))
            self.processing_tasks.append(asyncio.create_task(self._final_text_processor(), name="final"))
            self.processing_tasks.append(asyncio.create_task(self._response_handler(), name="response"))
            self.processing_tasks.append(asyncio.create_task(self._cleanup_manager(), name="cleanup"))

            logger.info(f"âœ… å¯åŠ¨äº† {len(self.processing_tasks)} ä¸ªå¤„ç†ä»»åŠ¡")
            
            # ä¿¡å·å¤„ç†
            def signal_handler(signum, frame):
                logger.info("ğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å·")
                self.running = False
            
            signal.signal(signal.SIGINT, signal_handler)
            signal.signal(signal.SIGTERM, signal_handler)
            
            try:
                while self.running:
                    await asyncio.sleep(1)
                    
                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                    for task in self.processing_tasks:
                        if task.done() and not task.cancelled():
                            exception = task.exception()
                            if exception:
                                logger.error(f"ä»»åŠ¡ {task.get_name()} å¼‚å¸¸: {exception}")
                                # é‡å¯å¤±è´¥çš„ä»»åŠ¡
                                await self._restart_failed_task(task)
                
            except Exception as e:
                logger.error(f"ä¸»å¾ªç¯é”™è¯¯: {e}")
            finally:
                await self._graceful_shutdown()
                
        except Exception as e:
            logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
            await self.stop()
    
    async def _restart_failed_task(self, failed_task):
        """é‡å¯å¤±è´¥çš„ä»»åŠ¡"""
        try:
            task_name = failed_task.get_name()
            logger.info(f"ğŸ”„ é‡å¯ä»»åŠ¡: {task_name}")
            
            # ç§»é™¤å¤±è´¥çš„ä»»åŠ¡
            self.processing_tasks.remove(failed_task)
            
            # é‡æ–°åˆ›å»ºä»»åŠ¡
            if task_name == "partial":
                new_task = asyncio.create_task(self._partial_text_processor(), name="partial")
            elif task_name == "final":
                new_task = asyncio.create_task(self._final_text_processor(), name="final")
            elif task_name == "response":
                new_task = asyncio.create_task(self._response_handler(), name="response")
            elif task_name == "cleanup":
                new_task = asyncio.create_task(self._cleanup_manager(), name="cleanup")
            else:
                return
            
            self.processing_tasks.append(new_task)
            logger.info(f"âœ… ä»»åŠ¡é‡å¯æˆåŠŸ: {task_name}")
            
        except Exception as e:
            logger.error(f"é‡å¯ä»»åŠ¡å¤±è´¥: {e}")
    
    async def _graceful_shutdown(self):
        """ä¼˜é›…å…³é—­"""
        logger.info("ğŸ›‘ å¼€å§‹ä¼˜é›…å…³é—­...")
        self.running = False
        
        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in self.processing_tasks:
            if not task.done():
                task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        try:
            await asyncio.wait_for(
                asyncio.gather(*self.processing_tasks, return_exceptions=True),
                timeout=5.0
            )
        except asyncio.TimeoutError:
            logger.warning("éƒ¨åˆ†ä»»åŠ¡æœªèƒ½åŠæ—¶å®Œæˆ")
        
        await self.stop()
        logger.info("âœ… ä¼˜é›…å…³é—­å®Œæˆ")
    
    async def _init_speech_recognition(self):
        """åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«"""
        logger.info("ğŸ™ï¸ åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
        
        try:
            import azure.cognitiveservices.speech as speechsdk
            
            speech_config = speechsdk.SpeechConfig(
                subscription=config.azure.speech_key,
                region=config.azure.speech_region
            )
            speech_config.speech_recognition_language = "zh-CN"
            
            audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
            self.recognizer = speechsdk.SpeechRecognizer(
                speech_config=speech_config,
                audio_config=audio_config
            )
            
            def on_recognizing(evt):
                if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:
                    partial_text = evt.result.text.strip()
                    if partial_text and len(partial_text) >= 4:
                        try:
                            if not self.partial_text_queue.full():
                                self.partial_text_queue.put_nowait({
                                    'text': partial_text,
                                    'timestamp': time.time(),
                                    'id': str(uuid.uuid4())[:8]
                                })
                        except:
                            pass
            
            def on_recognized(evt):
                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
                    final_text = evt.result.text.strip()
                    if final_text and len(final_text) > 1:
                        try:
                            if not self.final_text_queue.full():
                                self.final_text_queue.put_nowait({
                                    'text': final_text,
                                    'timestamp': time.time(),
                                    'id': str(uuid.uuid4())[:8]
                                })
                        except:
                            pass
            
            self.recognizer.recognizing.connect(on_recognizing)
            self.recognizer.recognized.connect(on_recognized)
            
            self.recognizer.start_continuous_recognition()
            logger.info("âœ… è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _init_openai(self):
        """åˆå§‹åŒ–OpenAI"""
        logger.info("ğŸ¤– åˆå§‹åŒ–OpenAI...")
        
        try:
            import openai
            self.openai_client = openai.AsyncOpenAI(api_key=config.openai.api_key)
            
            # æµ‹è¯•è¿æ¥
            test_response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": "æµ‹è¯•"}],
                max_tokens=5
            )
            
            if test_response.choices:
                logger.info("âœ… OpenAIè¿æ¥æˆåŠŸ")
            else:
                raise Exception("OpenAIæµ‹è¯•å¤±è´¥")
                
        except Exception as e:
            logger.error(f"OpenAIåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _init_openai_memory(self):
        """åˆå§‹åŒ–OpenAIè®°å¿†ç³»ç»Ÿ"""
        try:
            logger.info("ğŸ§  åˆå§‹åŒ–OpenAIè®°å¿†ç³»ç»Ÿ...")
            
            from openai_memory_manager import OpenAIMemoryManager
            
            self.openai_memory_manager = OpenAIMemoryManager(
                openai_client=self.openai_client,
                data_dir="data/openai_memory"
            )
            
            # æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡
            stats = await self.openai_memory_manager.get_memory_stats()
            logger.info(f"ğŸ“Š è®°å¿†ç»Ÿè®¡: {stats['total_memories']} æ¡è®°å¿†")
            
            if stats['by_type']:
                type_info = ", ".join([f"{k}: {v}" for k, v in stats['by_type'].items()])
                logger.info(f"ğŸ“‹ è®°å¿†ç±»å‹åˆ†å¸ƒ: {type_info}")
            
            self.memory_enabled = True
            logger.info("âœ… OpenAIè®°å¿†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"OpenAIè®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.memory_enabled = False
            self.openai_memory_manager = None
    
    async def _partial_text_processor(self):
        """éƒ¨åˆ†æ–‡æœ¬å¤„ç†å™¨"""
        while self.running:
            try:
                if not self.partial_text_queue.empty():
                    data = self.partial_text_queue.get_nowait()
                    await self._handle_partial_text(data)
                else:
                    await asyncio.sleep(0.05)
            except Exception as e:
                if self.running:
                    logger.error(f"å¤„ç†éƒ¨åˆ†æ–‡æœ¬é”™è¯¯: {e}")
                await asyncio.sleep(0.2)
    
    async def _handle_partial_text(self, data):
        """å¤„ç†éƒ¨åˆ†æ–‡æœ¬"""
        try:
            partial_text = data['text']
            text_id = data['id']
            timestamp = data['timestamp']
            
            # å†·å´æ—¶é—´æ£€æŸ¥
            if text_id in self.last_thinking_time:
                if timestamp - self.last_thinking_time[text_id] < self.thinking_cooldown:
                    return
            
            logger.debug(f"ğŸ§ å®æ—¶[{text_id}]: {partial_text}")
            
            if self._should_start_thinking(partial_text):
                logger.info(f"ğŸ§  æ„æ€[{text_id}]: {partial_text}")
                self.last_thinking_time[text_id] = timestamp
                
                # æ¸…ç†æ—§çš„æ€è€ƒä»»åŠ¡
                await self._cleanup_old_thinking_tasks(text_id)
                
                # å¯åŠ¨æ–°çš„æ€è€ƒ
                if text_id not in self.thinking_tasks:
                    self.thinking_tasks[text_id] = asyncio.create_task(
                        self._smart_thinking(partial_text, text_id)
                    )
                
        except Exception as e:
            logger.error(f"å¤„ç†éƒ¨åˆ†æ–‡æœ¬å¤±è´¥: {e}")
    
    async def _cleanup_old_thinking_tasks(self, current_id):
        """æ¸…ç†æ—§çš„æ€è€ƒä»»åŠ¡"""
        try:
            # ä¿ç•™æœ€è¿‘çš„2ä¸ªä»»åŠ¡
            task_ids = list(self.thinking_tasks.keys())
            if len(task_ids) > 2:
                for old_id in task_ids[:-2]:
                    if old_id != current_id and old_id in self.thinking_tasks:
                        self.thinking_tasks[old_id].cancel()
                        del self.thinking_tasks[old_id]
        except Exception as e:
            logger.debug(f"æ¸…ç†æ€è€ƒä»»åŠ¡å¤±è´¥: {e}")
    
    def _should_start_thinking(self, text):
        """åˆ¤æ–­æ˜¯å¦å¼€å§‹æ€è€ƒ"""
        if len(text) < 6:
            return False
        
        triggers = [
            'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'å¦‚ä½•',
            'èƒ½ä¸èƒ½', 'å¯ä»¥', 'ä¼šä¸ä¼š', 'æ˜¯ä¸æ˜¯'
        ]
        
        questions = ['ï¼Ÿ', '?', 'å—', 'å‘¢']
        
        has_trigger = any(t in text for t in triggers)
        has_question = any(q in text for q in questions)
        
        return has_trigger or has_question
    
    async def _smart_thinking(self, partial_text, text_id):
        """æ™ºèƒ½æ€è€ƒ"""
        try:
            prompt = f"ç”¨æˆ·å¯èƒ½æƒ³é—®ï¼š'{partial_text}' ç®€å•é¢„åˆ¤ï¼ˆ5å­—å†…ï¼‰ï¼š"
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=15,
                temperature=0.7
            )
            
            if response.choices:
                thought = response.choices[0].message.content.strip()
                self.partial_thoughts[text_id] = {
                    'thought': thought,
                    'partial_text': partial_text,
                    'timestamp': time.time()
                }
                logger.info(f"âš¡ é¢„åˆ¤[{text_id}]: {thought}")
            
        except asyncio.CancelledError:
            pass
        except Exception as e:
            logger.debug(f"æ€è€ƒå¤±è´¥[{text_id}]: {e}")
        finally:
            # æ¸…ç†ä»»åŠ¡å¼•ç”¨
            if text_id in self.thinking_tasks:
                del self.thinking_tasks[text_id]
    
    async def _final_text_processor(self):
        """æœ€ç»ˆæ–‡æœ¬å¤„ç†å™¨"""
        while self.running:
            try:
                if not self.final_text_queue.empty():
                    data = self.final_text_queue.get_nowait()
                    await self._handle_final_text(data)
                else:
                    await asyncio.sleep(0.05)
            except Exception as e:
                if self.running:
                    logger.error(f"å¤„ç†å®Œæ•´æ–‡æœ¬é”™è¯¯: {e}")
                await asyncio.sleep(0.2)
    
    def _check_force_record_keywords(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«å¼ºåˆ¶è®°å½•å…³é”®è¯"""
        force_keywords = [
            "è®°å½•ä¸€ä¸‹", "è®°ä½", "è®°ä¸‹æ¥", "ä¿å­˜ä¸€ä¸‹", 
            "æ·»åŠ åˆ°è®°å¿†", "è®°å½•", "å­˜å‚¨", "è®°ä¸‹",
            "åˆ«å¿˜äº†", "è¦è®°ä½", "å¸®æˆ‘è®°ä¸€ä¸‹"
        ]
        
        return any(keyword in text for keyword in force_keywords)

    def _extract_content_after_keywords(self, text: str) -> str:
        """æå–å¼ºåˆ¶è®°å½•å…³é”®è¯åçš„å†…å®¹"""
        force_keywords = ["è®°å½•ä¸€ä¸‹", "è®°ä½", "è®°ä¸‹æ¥", "ä¿å­˜ä¸€ä¸‹", "è®°å½•", "è®°ä¸‹"]
        
        for keyword in force_keywords:
            if keyword in text:
                # æ‰¾åˆ°å…³é”®è¯ä½ç½®ï¼Œæå–åé¢çš„å†…å®¹
                index = text.find(keyword) + len(keyword)
                content = text[index:].strip()
                if content:
                    return content
        
        return text  # å¦‚æœæ²¡æ‰¾åˆ°å…³é”®è¯ï¼Œè¿”å›åŸæ–‡

    async def _handle_final_text(self, data):
        """å¤„ç†å®Œæ•´æ–‡æœ¬"""
        try:
            final_text = data['text']
            text_id = data['id']
            timestamp = data['timestamp']
            
            # æ£€æŸ¥å¯¹è¯æ®µè½
            if timestamp - self.last_speech_time > self.silence_threshold:
                logger.info("ğŸ”„ æ–°å¯¹è¯æ®µè½")
                self.speech_segments = []
            
            self.speech_segments.append({
                'text': final_text,
                'timestamp': timestamp,
                'id': text_id
            })
            
            self.last_speech_time = timestamp
            logger.info(f"ğŸ—£ï¸  å®Œæ•´[{text_id}]: {final_text}")
            
            # === OpenAIè®°å¿†å¤„ç† ===
            if self.memory_enabled and self.openai_memory_manager:
                try:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¼ºåˆ¶è®°å½•å…³é”®è¯
                    force_record = self._check_force_record_keywords(final_text)
                    
                    # å¼‚æ­¥å¤„ç†è®°å¿†å­˜å‚¨ï¼Œä¸é˜»å¡ä¸»æµç¨‹
                    asyncio.create_task(self._process_memory(final_text, force_record=force_record))
                except Exception as e:
                    logger.debug(f"è®°å¿†å¤„ç†å¤±è´¥: {e}")
            
            if self._should_respond(final_text):
                logger.info(f"ğŸ¤– éœ€è¦å›åº”[{text_id}]")
                
                context_text = self._build_context()
                prior_thought = self.partial_thoughts.get(text_id, {})
                
                try:
                    await self.response_queue.put({
                        'text': context_text,
                        'final_text': final_text,
                        'timestamp': timestamp,
                        'id': text_id,
                        'prior_thought': prior_thought
                    })
                except asyncio.QueueFull:
                    logger.warning(f"å“åº”é˜Ÿåˆ—æ»¡[{text_id}]")
            
            # æ¸…ç†æ€è€ƒä»»åŠ¡
            if text_id in self.thinking_tasks:
                self.thinking_tasks[text_id].cancel()
                del self.thinking_tasks[text_id]
            
        except Exception as e:
            logger.error(f"å¤„ç†å®Œæ•´æ–‡æœ¬å¤±è´¥: {e}")
    
    async def _process_memory(self, text: str, force_record: bool = False):
        """å¼‚æ­¥å¤„ç†è®°å¿† - æ·»åŠ AIå›ç­”è¿‡æ»¤å’Œå¼ºåˆ¶è®°å½•åŠŸèƒ½"""
        try:
            context = self._build_context()  # æå‰å®šä¹‰context
            
            if force_record:
                # å¼ºåˆ¶è®°å½•æ¨¡å¼ï¼šæå–å…³é”®è¯åçš„å†…å®¹
                cleaned_text = self._extract_content_after_keywords(text)
                success = await self.openai_memory_manager.force_store(cleaned_text, context)
                if success:
                    logger.info(f"ğŸ”’ å¼ºåˆ¶è®°å½•: {cleaned_text}")
                return
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·åœ¨å¤è¿°AIçš„å›ç­”
            if self._is_likely_ai_echo(text):
                logger.debug(f"ğŸš« è·³è¿‡AIå›ç­”å¤è¿°: {text}")
                return
                
            success = await self.openai_memory_manager.extract_and_store(text, context)
            
            if success:
                logger.debug(f"âœ… è®°å¿†å¤„ç†æˆåŠŸ: {text[:30]}...")
            
        except Exception as e:
            logger.debug(f"è®°å¿†å¤„ç†å¼‚å¸¸: {e}")

    def _is_likely_ai_echo(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯ç”¨æˆ·å¤è¿°AIå›ç­”"""
        # æ£€æŸ¥æœ€è¿‘çš„AIå›ç­”
        recent_responses = getattr(self, 'recent_ai_responses', [])
        
        for ai_response in recent_responses[-3:]:  # æ£€æŸ¥æœ€è¿‘3ä¸ªå›ç­”
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self._text_similarity(text, ai_response)
            if similarity > 0.7:  # 70%ç›¸ä¼¼åº¦è®¤ä¸ºæ˜¯å¤è¿°
                return True
        
        # æ£€æŸ¥å…¸å‹çš„å¤è¿°æ¨¡å¼
        echo_patterns = [
            "æˆ‘å«", "æˆ‘æ˜¯", "æˆ‘çš„", "æˆ‘åœ¨", "æˆ‘ä½", "æˆ‘å·¥ä½œ",
            "æˆ‘å¦ˆå¦ˆ", "æˆ‘çˆ¸çˆ¸", "æˆ‘å–œæ¬¢"
        ]
        
        # å¦‚æœåŒ…å«å¤šä¸ªè‡ªæˆ‘æè¿°è¯ï¼Œå¯èƒ½æ˜¯å¤è¿°
        pattern_count = sum(1 for pattern in echo_patterns if pattern in text)
        if pattern_count >= 2 and len(text) < 50:
            return True
        
        return False

    def _text_similarity(self, text1: str, text2: str) -> float:
        """ç®€å•æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—"""
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    def _should_respond(self, text):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å›åº”"""
        questions = ['ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'å¦‚ä½•', 'å—', 'å‘¢', 'ï¼Ÿ', '?']
        requests = ['å¸®æˆ‘', 'å‘Šè¯‰æˆ‘', 'æ¨è', 'å»ºè®®']
        excludes = ['ä½ å¥½', 'å†è§', 'è°¢è°¢']
        
        has_question = any(q in text for q in questions)
        has_request = any(r in text for r in requests)
        is_excluded = any(e in text for e in excludes)
        
        return (has_question or has_request) and not is_excluded and len(text) > 3
    
    def _build_context(self):
        """æ„å»ºä¸Šä¸‹æ–‡"""
        if not self.speech_segments:
            return ""
        recent = self.speech_segments[-3:]  # æœ€è¿‘3ä¸ªç‰‡æ®µ
        return ' '.join([seg['text'] for seg in recent])
    
    async def _response_handler(self):
        """å“åº”å¤„ç†å™¨"""
        logger.info("ğŸ”„ å“åº”å¤„ç†å™¨å¯åŠ¨")
        
        while self.running:
            try:
                response_data = await asyncio.wait_for(
                    self.response_queue.get(),
                    timeout=1.0
                )
                
                if not self.running:
                    break
                
                async with self.response_semaphore:
                    task_id = response_data['id']
                    task = asyncio.create_task(
                        self._generate_and_speak(response_data),
                        name=f"resp_{task_id}"
                    )
                    
                    self.active_responses[task_id] = task
                    logger.info(f"ğŸ¯ å¯åŠ¨å›ç­”[{task_id}]")
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                if self.running:
                    logger.error(f"å“åº”å¤„ç†é”™è¯¯: {e}")
                await asyncio.sleep(0.5)
    
    async def _generate_and_speak(self, response_data):
        """ç”Ÿæˆå¹¶æ’­æ”¾å›ç­”"""
        task_id = response_data['id']
        
        try:
            if not self.running:
                return
                
            final_text = response_data['final_text']
            context = response_data.get('text', '')
            prior_thought = response_data.get('prior_thought', {})
            
            logger.info(f"ğŸ’­ ç”Ÿæˆå›ç­”[{task_id}]: {final_text}")
            
            # === é¦–å…ˆå°è¯•OpenAIè®°å¿†å›ç­” ===
            openai_response = ""
            used_memory_ids = []
            if self.memory_enabled and self.openai_memory_manager:
                try:
                    openai_response, used_memory_ids = await self.openai_memory_manager.smart_search_and_respond(
                        final_text, context
                    )
                except Exception as e:
                    logger.debug(f"OpenAIè®°å¿†å›ç­”å¤±è´¥: {e}")

            full_response = ""
            if openai_response and len(openai_response.strip()) > 5:
                logger.info(f"ğŸ§  OpenAIè®°å¿†å›ç­”[{task_id}]: {openai_response}")
                full_response = openai_response
                
                # ç«‹å³è®°å½•ä½¿ç”¨äº†è®°å¿†çš„æ­£é¢åé¦ˆ
                if used_memory_ids:
                    for memory_id in used_memory_ids:
                        asyncio.create_task(
                            self.openai_memory_manager.importance_adjuster.track_user_feedback(
                                memory_id, True
                            )
                        )
                    logger.debug(f"ğŸ“ˆ è®°å½•æ­£é¢åé¦ˆ: {len(used_memory_ids)} æ¡è®°å¿†")
            else:
                # å¤‡ç”¨AIå›ç­”é€»è¾‘
                thought_hint = ""
                if prior_thought and prior_thought.get('thought'):
                    thought_hint = f" (é¢„åˆ¤:{prior_thought['thought']})"
                    
                prompt = f"""ç®€æ´å›ç­”ï¼š{final_text}{thought_hint}

    è¦æ±‚ï¼š1-2å¥è¯ï¼Œå®ç”¨ç›´æ¥ï¼š"""
                
                try:
                    stream = await self.openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": prompt}],
                        max_tokens=80,
                        temperature=0.6,
                        stream=True
                    )
                    
                    async for chunk in stream:
                        if not self.running:
                            break
                        if chunk.choices[0].delta.content:
                            full_response += chunk.choices[0].delta.content
                        
                except Exception as e:
                    logger.error(f"OpenAIç”Ÿæˆå¤±è´¥[{task_id}]: {e}")
                    full_response = "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”ã€‚"
            
            # æ’­æ”¾å›ç­”
            if full_response.strip() and self.running:
                logger.info(f"ğŸ¯ å›ç­”[{task_id}]: {full_response}")
                await self.tts_engine.speak_streaming(full_response, task_id)
            
            logger.info(f"âœ… å›ç­”å®Œæˆ[{task_id}]")
            

            
                    
        except Exception as e:
            if self.running:
                logger.error(f"ç”Ÿæˆå›ç­”å¤±è´¥[{task_id}]: {e}")
        finally:
            if task_id in self.active_responses:
                del self.active_responses[task_id]
        
    
    async def _cleanup_manager(self):
        """æ¸…ç†ç®¡ç†å™¨"""
        while self.running:
            try:
                await asyncio.sleep(10)  # æ¯10ç§’æ¸…ç†ä¸€æ¬¡
                current_time = time.time()
                
                # æ¸…ç†è¿‡æœŸçš„æ€è€ƒç»“æœ
                expired_thoughts = [
                    tid for tid, data in self.partial_thoughts.items()
                    if current_time - data['timestamp'] > 30
                ]
                
                for tid in expired_thoughts:
                    del self.partial_thoughts[tid]
                
                # æ¸…ç†è¿‡æœŸçš„æ€è€ƒæ—¶é—´
                expired_times = [
                    tid for tid, timestamp in self.last_thinking_time.items()
                    if current_time - timestamp > 60
                ]
                
                for tid in expired_times:
                    del self.last_thinking_time[tid]
                
                # æ¸…ç†è¿‡æœŸçš„å¯¹è¯ç‰‡æ®µ
                if current_time - self.last_speech_time > 60:
                    self.speech_segments = []
                
                # === æ–°å¢ï¼šè®°å¿†ç³»ç»Ÿæ¸…ç† ===
                if self.memory_enabled and self.openai_memory_manager:
                    # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡æ—§è®°å¿†
                    if current_time % 3600 < 10:  # 1å°æ—¶ = 3600ç§’
                        try:
                            await self.openai_memory_manager.cleanup_old_memories(days=30)
                        except Exception as e:
                            logger.debug(f"è®°å¿†æ¸…ç†å¤±è´¥: {e}")
                
                # çŠ¶æ€æŠ¥å‘Š
                if len(self.active_responses) > 0:
                    logger.debug(f"ğŸ“Š æ´»è·ƒå›ç­”: {len(self.active_responses)}")
                    
            except Exception as e:
                if self.running:
                    logger.error(f"æ¸…ç†ç®¡ç†é”™è¯¯: {e}")
    
    async def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        logger.info("ğŸ›‘ åœæ­¢ç³»ç»Ÿ...")
        self.running = False
        
        # åœæ­¢TTS
        await self.tts_engine.stop()
        
        # === æ–°å¢ï¼šå…³é—­OpenAIè®°å¿†ç³»ç»Ÿ ===
        if hasattr(self, 'openai_memory_manager') and self.openai_memory_manager:
            try:
                self.openai_memory_manager.close()
                logger.info("âœ… OpenAIè®°å¿†ç³»ç»Ÿå·²å…³é—­")
            except Exception as e:
                logger.debug(f"å…³é—­è®°å¿†ç³»ç»Ÿå¤±è´¥: {e}")
        
        # å–æ¶ˆæ´»è·ƒä»»åŠ¡
        for task_id, task in list(self.active_responses.items()):
            if not task.done():
                task.cancel()
        
        for task_id, task in list(self.thinking_tasks.items()):
            if not task.done():
                task.cancel()
        
        # åœæ­¢è¯­éŸ³è¯†åˆ«
        if self.recognizer:
            try:
                self.recognizer.stop_continuous_recognition()
                logger.info("âœ… è¯­éŸ³è¯†åˆ«å·²åœæ­¢")
            except:
                pass
        
        logger.info("âœ… ç³»ç»Ÿå®Œå…¨åœæ­¢")

async def main():
    """ä¸»å‡½æ•°"""
    enhancer = FixedVoiceEnhancer()
    
    try:
        await enhancer.start()
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸: {e}")
    finally:
        if enhancer.running:
            await enhancer.stop()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§ï¼")
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")
    finally:
        print("âœ… ç¨‹åºå·²é€€å‡º")